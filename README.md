# Statistics Blogs
This collection aims to gather blogs and other online resources explaining statistical concepts simply and clearly.


## General Concepts
[Probablity vs Statistics](https://stats.stackexchange.com/questions/665/whats-the-difference-between-probability-and-statistics)\
[Likelihoodist, Bayesian, and Frequentist Methods](http://gandenberger.org/2014/07/21/intro-to-statistical-methods/)\
[Mathematical Basis of Bayesian vs Frequentist Debate](https://stats.stackexchange.com/questions/230415/is-there-any-mathematical-basis-for-the-bayesian-vs-frequentist-debate)

## Probability 
[Expected Values](https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/79a290ef627e8f975fcbf93ff869d8ec_MIT18_05S14_Reading4b.pdf)\
[Properties of Expected Value](https://en.wikipedia.org/wiki/Expected_value#Properties)\
[Variance Values](https://ocw.mit.edu/courses/18-05-introduction-to-probability-and-statistics-spring-2014/b09f8047e25079e59d379a4d9782b621_MIT18_05S14_Reading5a.pdf)\
[Properties of Variance](https://en.wikipedia.org/wiki/Variance#Properties)\
[Set theory](https://stats.libretexts.org/Bookshelves/Probability_Theory/Probability_Mathematical_Statistics_and_Stochastic_Processes_(Siegrist)/01%3A_Foundations/1.01%3A_Sets)\
[Venn Diagrams](https://www.researchgate.net/figure/A-Venn-diagram-of-unions-and-intersections-for-two-sets-A-and-B-and-their-complements_fig1_332453167)\
[Probability Axioms](https://math.unm.edu/~james/Probability2.pdf)\
[pdf,cdf,ppt](https://www.itl.nist.gov/div898/handbook/eda/section3/eda362.htm)\
[Quantiles](https://prepnuggets.com/glossary/quantile/)\
[Experiment, Sample space, Event, Probability function, Random variable](http://www.cs.toronto.edu/~anikolov/CSC473W20/Probability.pdf)\
[Properties of cdf and pdf](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading5b.pdf)\
[Transformations of Random Variables](http://www2.econ.iastate.edu/classes/econ671/hallam/documents/Transformations.pdf)\
[Joint Probability Distribution](https://en.wikipedia.org/wiki/Joint_probability_distribution)\
[Maximum Likelihood Estimation](https://online.stat.psu.edu/stat504/lesson/1/1.5)\


### Bayesian Statistics
[Bayesian Learning](https://www.analyticsvidhya.com/blog/2016/06/bayesian-statistics-beginners-simple-english/)\
[A/B testing, Bayesian](https://app.datacamp.com/workspace/w/cff27c6e-b68b-42df-ad82-9b0d029b7f0d)\
[Hierarchical Modeling](http://mfviz.com/hierarchical-models/)

#### Bayesian Samplers
[Rejection Sampling](https://towardsdatascience.com/what-is-rejection-sampling-1f6aff92330d)\
[Importance Sampling](https://towardsdatascience.com/importance-sampling-introduction-e76b2c32e744)\
[Inverse Transform Sampling](https://towardsdatascience.com/an-insight-on-generating-samples-from-a-custom-probability-density-function-d0a06c290c54)\
[The Metropolis-hasting algorithm](https://medium.com/towards-data-science/mcmc-intuition-for-everyone-5ae79fff22b1)[ and also](https://www2.math.upenn.edu/~bmor/Metropolis.pdf)\
[Gibbs Sampling](https://towardsdatascience.com/gibbs-sampling-explained-b271f332ed8d)\
[Gibbs Sampling as a Special Case of Metropolis–Hastings](https://gregorygundersen.com/blog/2020/02/23/gibbs-sampling/)


### Correlation 
[Covariance](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading7b.pdf)\
[Covariance and Correlation](https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading7b.pdf)\
[Pearson Correlation](https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Statistics_Using_Technology_(Kozak)/10%3A_Regression_and_Correlation/10.02%3A_Correlation)\
[Partial Correlation](https://towardsdatascience.com/partial-correlation-508353cd8b5)\
[Kendall Rank Correlation](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient)\
[Wald Wolfowitz Run Test](https://accendoreliability.com/the-wald-wolfowitz-run-test-for-two-small-samples/)


### Probability Distributions
[Univariate distributions](http://www.math.wm.edu/~leemis/chart/UDR/UDR.html)\
[Bernoulli distribution](https://en.wikipedia.org/wiki/Bernoulli_distribution)\
[Binomial distribution](https://en.wikipedia.org/wiki/Binomial_distribution)\
[Continous Uniform Distribution](https://en.wikipedia.org/wiki/Continuous_uniform_distribution)\
[Poission distribution](https://www.le.ac.uk/users/dsgp1/COURSES/LEISTATS/poisson.pdf)\
[Exponential distribution](https://stats.stackexchange.com/questions/2092/relationship-between-poisson-and-exponential-distribution)

## Hypothesis Testing
### Z-test
[Law of Large Numbers](https://www.probabilitycourse.com/chapter7/7_1_1_law_of_large_numbers.php)\
[Central Limit Theorem](https://statisticsbyjim.com/basics/central-limit-theorem/)\
[Z-Score](https://statisticsbyjim.com/basics/z-score/)\
[One Proportion Z-test](https://www.statology.org/one-proportion-z-test/)\
[Two Sample Z-test](http://www.stat.ucla.edu/~cochran/stat10/winter/lectures/lect21.html)\
[p-value](https://www.scribbr.com/statistics/p-value/)\
[Right, Left, and Two tailed test](https://courses.lumenlearning.com/wm-concepts-statistics/chapter/hypothesis-test-for-difference-in-two-population-proportions-4-of-6/)\
[Type I and Type II Errors](https://www.scribbr.com/statistics/type-i-and-type-ii-errors/)
### t-rest
[t-test](https://statisticsbyjim.com/hypothesis-testing/t-tests-t-values-t-distributions-probabilities/)\
[Paired t-test](https://online.stat.psu.edu/stat415/lesson/10/10.3)\
[Two Sample t-test, pooled and unpooled variances](https://online.stat.psu.edu/stat500/lesson/7/7.3/7.3.1)
### Chi-square test
[Chi-square distribution](https://en.wikipedia.org/wiki/Chi-squared_distribution)\
[Chi-square test proof](https://ocw.mit.edu/courses/mathematics/18-443-statistics-for-applications-fall-2006/lecture-notes/lecture11.pdf)\
[Chi-square test](https://en.wikipedia.org/wiki/Chi-squared_test)

### Non-Paramteric Tests 
[Nonparametric Tests vs. Parametric Tests](https://statisticsbyjim.com/hypothesis-testing/nonparametric-parametric-tests)\
[Mann Whitney U Test (Wilcoxon Rank Sum Test)](https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/bs704_nonparametric4.html)\
[Wilcoxon Signed Rank Test](https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/BS704_Nonparametric5.html#headingtaglink_3)\
[Sign Test](https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/BS704_Nonparametric5.html#headingtaglink_3)\
[The Kruskal-Wallis Test](https://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/BS704_Nonparametric7.html)\
[Permutation Test](https://www.jwilber.me/permutationtest/)

### Bootstrapping
[Bootstrapping](https://online.stat.psu.edu/stat500/lesson/11/11.2)


## Linear Regression
[Ordinary Least Squares through minimising the sum of square errors](https://www.timlrx.com/blog/notes-on-regression-ols)\
[Projection and Orthogonality](https://www.timlrx.com/blog/notes-on-regression-geometry)\
[Method of Moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics))\
[Linear Regression as Maximum Likelihoods](https://www.timlrx.com/blog/notes-on-regression-maximum-likelihood)
[Regression vs Correlation coefficients](https://www.graphpad.com/support/faq/what-is-the-difference-between-correlation-and-linear-regression/)\
[Bayesian Linear Regression](https://www.inovex.de/de/blog/bayesian-linear-regression-in-machine-learning/)\
[Applying SVD to Linear Regression](https://www.timlrx.com/blog/notes-on-regression-singular-vector-decomposition)\
[Linear Regression Metrics](https://towardsdatascience.com/how-to-choose-the-best-linear-regression-model-a-comprehensive-guide-for-beginners-754480768467)\
[Variance Inflation Factors](https://statisticsbyjim.com/regression/variance-inflation-factors/)
[Multi Linear Regression and multicollinearity](https://towardsdatascience.com/multiple-linear-regression-8cf3bee21d8b)[and also](https://statisticsbyjim.com/regression/multicollinearity-in-regression-analysis/)\


### Multiple Hypothesis Testing
#### F-Test
[F-distribution](https://en.wikipedia.org/wiki/F-distribution)\
[General Linear F-test](https://online.stat.psu.edu/stat462/node/135/)\
[Calculating F-Statistic](https://www.mattblackwell.org/files/teaching/ftests.pdf)\
[Coding Systems For Categorical Variables](https://stats.oarc.ucla.edu/spss/faq/coding-systems-for-categorical-variables-in-regression-analysis/)
#### ANOVA
[What is ANOVA](https://www.spss-tutorials.com/anova-what-is-it/)\
[One Way Anova](https://www.itl.nist.gov/div898/handbook/prc/section4/prc431.htm)\
[ANOVA mathematical model](https://www.itl.nist.gov/diBv898/handbook/prc/section4/prc432.htm)\
[ANOVA Assumptions](https://sites.ualberta.ca/~lkgray/uploads/7/3/6/2/7362679/slides_-_anova_assumptions.pdf)\
[Linear Combinations and Contrasts](http://users.stat.umn.edu/~helwig/notes/aov1-Notes.pdf)\
[Fixed Effect, Random Effect and Mixed Effect models](https://stats.stackexchange.com/questions/4700/what-is-the-difference-between-fixed-effect-random-effect-and-mixed-effect-mode)\
[Factorial and Unbalanced ANOVA](http://users.stat.umn.edu/~helwig/notes/aov2-Notes.pdf)\
[ANCOVA](http://users.stat.umn.edu/~helwig/notes/acov-Notes.pdf)

#### Multiple Comparision Problem
[Multiple Comparison Problem](https://towardsdatascience.com/an-overview-of-methods-to-address-the-multiple-comparison-problem-310427b3ba92)\
[Bonferroni’s Correction](http://users.stat.umn.edu/~helwig/notes/aov1-Notes.pdf)\
[Holm’s Step-Down and Hochberg’s Step-Up Procedure](https://en.wikipedia.org/wiki/Family-wise_error_rate)\
[Studentized range distribution](https://en.wikipedia.org/wiki/Studentized_range_distribution)\
[Turkey's Range Test](http://users.stat.umn.edu/~helwig/notes/OneWayANOVA.pdf)

#### Multivariate Hypothesis Testing
[MANOVA](https://online.stat.psu.edu/stat505/lesson/8)\
[PCA](https://online.stat.psu.edu/stat505/lesson/11)\
[Factor Analysis](https://online.stat.psu.edu/stat505/lesson/12)\
[Canonical Analysis](https://online.stat.psu.edu/stat505/lesson/13)

#### Statistical Paradoxes
[Monty Hall](https://betterexplained.com/articles/understanding-the-monty-hall-problem/)\
[Russels Paradox](https://www.quora.com/What-in-laymans-terms-is-Russells-Paradox)


## Estimators
[Estimators](https://slideplayer.com/slide/16203181/)\
[Difference between estimator and statistics](https://stats.stackexchange.com/questions/47728/what-is-the-difference-between-an-estimator-and-a-statistic)


## Gaussian Process
[Gaussian Process](https://thegradient.pub/gaussian-process-not-quite-for-dummies/)

# Causal Inference
[Structural Causal Models](https://medium.data4sci.com/causal-inference-part-iv-structural-causal-models-df10a83be580)\
[Chains, and Forks](https://medium.data4sci.com/causal-inference-part-v-chains-and-forks-7b0b088c346e)\
[Colliders](https://medium.data4sci.com/causal-inference-part-vi-colliders-af07301c9a15)\
[d-separation](https://medium.data4sci.com/causal-inference-part-vii-d-separation-aa74e361d34e)\
[Model Testing and Causal Search](https://medium.data4sci.com/causal-inference-part-vii-d-separation-aa74e361d34e)\
[Interventions](https://medium.data4sci.com/causal-inference-part-ix-interventions-c3f94190191d)\
[The Adjustment Formula](https://medium.data4sci.com/causal-inference-part-x-the-adjustment-formula-f9668469d76)\
[Backdoor Criterion](https://medium.data4sci.com/causal-inference-part-xi-backdoor-criterion-e29627a1da0e)\
[Front-door Criterion](https://medium.data4sci.com/causal-inference-part-xii-front-door-criterion-38bec5172f3e)

# Machine Learning

## Decision Trees
[Decision Tree Learning](https://pages.cs.wisc.edu/~dpage/cs760/decision-trees.pdf)\
[ID3, C4.5, C5.0, CART decision tree difference](https://blog.actorsfit.com/a?ID=01800-16f8ea67-422e-4850-b0b0-3749e5181112)\
[C4.5 and C5.0 Algorithm](https://en.wikipedia.org/wiki/C4.5_algorithm)\
[ID3 Algorithm](https://towardsdatascience.com/decision-trees-for-classification-id3-algorithm-explained-89df76e72df1#:~:text=the%20ID3%20algorithm%20selects%20the%20best%20feature%20at%20each%20step%20while%20building%20a%20Decision%20tree.%0ABefore%20you%20ask%2C%20the%20answer%20to%20the%20question%3A%20%E2%80%98How%20does%20ID3%20select%20the%20best%20feature%3F%E2%80%99%20is%20that%20ID3%20uses%20Information%20Gain%20or%20just%20Gain%20to%20find%20the%20best%20feature.)\
[Pruning](https://towardsdatascience.com/build-better-decision-trees-with-pruning-8f467e73b107)\
[Gini Impurity, Entropy, Classification Error](https://sebastianraschka.com/faq/docs/decision-tree-binary.html)

## Ensemble Methods
[Ensemble methods: bagging, boosting and stacking](https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205)\
[Adaboost](https://towardsdatascience.com/understanding-adaboost-for-decision-tree-ff8f07d2851)\
[Gradient Boosting](https://www.geeksforgeeks.org/ml-gradient-boosting/)

## Explanation Methods
[Lime](https://christophm.github.io/interpretable-ml-book/lime.html)\
[Shapley and Shap](https://towardsdatascience.com/shap-shapley-additive-explanations-5a2a271ed9c3)\
[Counterfactual Explanations](https://christophm.github.io/interpretable-ml-book/counterfactual.html)

